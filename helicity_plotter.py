#!/usr/bin/python
"""
This script is intended to take data from self-assembled monolayer docking 
simulations, and generate apropriate plots.  The script reads a folder with 
subfolders containing the top decoys from a set of trials generated by another 
script, 'submit_script_gen'.

A note about octets: now they're quadrants. An older version of the script 
handled 7mers and 14mers together, whereas for the publication, I needed only
14mers, so I changed it around but never got around to beautifying.

Script for extracting data and making plots originally written by M. Pacella
Modified and expanded by J. H. Lubin
"""
import argparse
import operator
from os import getcwd, listdir, makedirs, walk
from os.path import basename, dirname, isdir, join, normpath
import pickle
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt 
import matplotlib.patches as mpat
from matplotlib import cm
import matplotlib.gridspec as gridspec
import numpy as np
from pylab import *
from scipy.interpolate import UnivariateSpline
from scipy.stats import gaussian_kde
# Following functions only used for calculating helicity
from rosetta import * 
from rosetta.core.scoring.dssp import Dssp
import rosetta.core.scoring.solid_surface
from glob import glob
import gzip

# parameter info, with default values
param_list = {	'fa_atr': 0.8, 'fa_rep': 0.44, 'fa_sol': 0.75, 
				'fa_intra_rep': 0.004, 'fa_elec': 0.7, 'pro_close': 1, 
				'hbond_sr_bb': 1.17, 'hbond_lr_bb':	1.17, 'hbond_bb_sc': 1.17, 
				'hbond_sc': 1.1, 'dslf_fa13': 1.0,	'rama': 0.2, 'omega': 0.5, 
				'fa_dun': 0.56, 'p_aa_pp': 0.32, 'ref': 1, 'lj_radius': 2.000, 
				'lj_wdepth': 0.1811, 'lk_dgfree': 1.5000, 'lk_lambda': 3.5000, 
				'lk_volume': 30.0000, 'range': 5, 'kcde': 0.52}


def parse_args():
	""" 
	Collect input arguments for helicity plotter. By default, the script will
	take a data file it has generated on a previous run and produce plots.
	-c is an option to calculate such a data file for a new dataset
	Parameters -p1 and -p2 can be entered manually, though by default, the
	script will read the folder name for parameter names, and finding none, 
	will assume baseline. 
	-bw will generate the plots in black and white, rather than default colors
	-s will silence the default output of PDB's being processed and plots made
	"""
	info = 'Make helicity plots for decoys generated by submit_script_gen'
	parser = argparse.ArgumentParser(description=info)
	parser.add_argument("folder", type=str, 
						help="What folder below the current working \
								directory do you want to use?")
	parser.add_argument("-c", "--calculate", action="store_true", 
						help="Use this option the first time handling a \
								dataset")
	parser.add_argument("-p1", "--parameter_1", type=str, 
						help="Manually enter a varied parameter for \
								calculation")
	parser.add_argument("-p2", "--parameter_2", type=str, 
						help="Manually enter second varied parameter for \
								calculation.")
	parser.add_argument("-bw", "--black_white", action="store_true", 
						help="Use this option to print the plots in black \
								and white")
	parser.add_argument("-sl", "--skip_local", action="store_true", 
						help="Make only parameter varition plots")
	args = parser.parse_args()

	return args

#############################################################################
"""Data management"""


class pose_helicity_data:
	"""
	This class is designed to hold helicity data from a single PDB.  

	Pose name will be the PDB name string. Peptide size, PDB score, and 
	helicity will be float values, with helicity being the count of helical 
	residues divided by two less than the peptide length. Leucine and lysine 
	distances and phis and psis will be lists with length matching the number 
	of each residue in the peptide. Helix and loop hist will be arrays of 
	length equal to the peptide size, counting whether each residue is helical 
	or not.  
	"""
	def __init__(self, pdb_file):
		self.pose_name = ''

		self.peptide_size = 0
		self.score = 0
		self.helicity = 0

		self.leucine_distances = []
		self.lysine_distances = []
		self.c_alpha_distances = []

		self.helix_hist = np.array([])
		self.loop_hist = np.array([])

		self.phis = []
		self.psis = []

		self.pose_helicity_analysis(pdb_file)

	def pose_helicity_analysis(self, pdb_file):
		"""
		Function takes input PDB file and exctacts multiple pieces of data, 
		including the name of the PDB file, the peptide length, the PDB score 
		(which includes any weight parameter changes), a count of helical 
		residues, lists of the distances between leucine and lysine residues 
		and the surface, arrays of length equal to the number of residues with 
		1's or 0's indicating whether a residue is helical, and the backbone 
		dihedrals.
		"""
		# Getting just the PDB file name from directory 
		self.pose_name = basename(pdb_file)
		print self.pose_name

		# Reading PDB file for secondary structure
		pose = pose_from_pdb(pdb_file)  # load a pose from the file
		first_protein_residue = pose.num_jump()+1

		# Getting peptide size
		self.peptide_size = pose.total_residue() + 1 - first_protein_residue

		# Getting the score of the current pdb
		self.score = self.read_score(pdb_file)

		# Initializing histogram lists (size is required)
		self.helix_hist = np.array([0] * self.peptide_size)
		self.loop_hist = np.array([0] * self.peptide_size)

		# Getting secondary structure, coordinates, dihedrals for each residue
		sec_struct = Dssp(pose)
		sec_struct.insert_ss_into_pose(pose)
		H_count = float(0)

		for resnum in range(first_protein_residue, pose.total_residue()+1):
			residue = resnum - first_protein_residue
			self.get_secstruct(pose, resnum, residue)

	def read_score(self, pdb_file):
		"""
		Reads the score from the text of a PDB file.  This yields the score 
		reflecting any altered weight parameters, rather than rescoring the 
		PDB with default weights. Searches PDB text from the bottom, since the 
		relevant line is near the end. The total score is the last item of 
		that line.
		"""
		# Read PDB file
		with gzip.open(pdb_file, 'r') as pdbgz:
			line_search = pdbgz.readlines()

		# Find line with pose scores
		for line in line_search[::-1]: 	
			line = line.rstrip()
			if line[0:4] == "pose":
				score_line = line
				break

		# Convert last portion of total score line to a float value
		total_score = float(score_line.split()[-1])

		return total_score

	def get_secstruct(self, pose, pdb_number, peptide_number):
		"""
		Inputs of a PDB file and a residue number, and returns whether the 
		residue is helical, the amino acid type, the distance from the 
		surface, and the backbone dihedrals.  Distance is determined based on 
		average of CD's for leucine and NZ for lysine. 
		"""
		# Getting residue secondary structure
		sec_struct_string = pose.secstruct()
		res_sec_struct = sec_struct_string[pdb_number-1]

		# Incorporating residue's secondary structure into histogram
		if res_sec_struct == 'H':
			self.helix_hist[peptide_number] += 1
			self.helicity += float(1)/(self.peptide_size -2)
			# Peptide size -2 because termini cannot be helical
		else:
			self.loop_hist[peptide_number] += 1

		# Gettng residue name
		res = pose.residue(pdb_number)
		res_name = res.name1()

		# Getting and adjusting the z coordinates
		if res_name == 'L': 	# average of carbon deltas for leucine
			z1 = res.atom('CD1').xyz().z
			z2 = res.atom('CD2').xyz().z
			z_val = self.adjust_surface_z(float(np.mean([z1, z2])), pose)
			self.leucine_distances.append(z_val)

		if res_name == 'K':  	# z coordinate of nitrogen for lysine
			z_val = self.adjust_surface_z(res.atom('NZ').xyz().z, pose)
			self.lysine_distances.append(z_val)

		c_a_z = self.adjust_surface_z(res.atom('CA').xyz().z, pose) 	# CA
		self.c_alpha_distances.append(c_a_z)

		# Getting backbone dihedrals, ignoring terminal residues
		if peptide_number not in [0, self.peptide_size-1]:
			self.phis.append(pose.phi(pdb_number))
			self.psis.append(pose.psi(pdb_number))

	def adjust_surface_z(self, z_value, pose):
		"""
		Takes a z coordinate of an LK peptide residue and corrects position.
		The z coordinate is adjusted because the surfaces are not at precisely 
		z = 0A. The average z coordinate for the top of the hydrophilic 
		surface is -17.868A. There was an error in early simulations where the 
		peptide may be above or below the hydrophobic surface (which is 
		symmetrical). The average z for the top of the hydrophobic surface is 
		-19.064A, and for the bottom is -30.964.  The center of the surface 
		was therefore considered -25.
		"""
		if pose.residue(1).name() in ['COO', 'COH']: 	# hydrophilic surface
		# Surface is always before peptide in PDB file
			coordinate = z_value + 17.868
		elif z_value > -25: 			# above hydrophobic surface
			coordinate = z_value + 19.064
		else: 						# below hydrophobic surface
			coordinate = -z_value - 30.964

		return coordinate


class folder_helicity_data:
	"""
	This class is designed to take in and organize data from individual decoys

	Test condition and both parameters will be strings; the parameter values 
	and set helicity mean standard deviation will be float values with the 
	parameter defaults at 0 signifying baseline; helix count and loop count 
	will be lists with length matching the peptide length, indicating degree 
	of helicity at each residue; file names, scores, helicities will be lists 
	of the respective data for each PDB in the folder; L_ and K_ distances 
	will be lists of length equal times the product of peptide length and the 
	number of PDB's.
	"""
	def __init__(self, place, parameter_1, parameter_2):
		self.location = place
		self.folder_name = basename(place)

		self.parameter_1 = parameter_1
		self.parameter_1_value = self.name_to_num(parameter_1)

		self.parameter_2 = parameter_2
		self.parameter_2_value = self.name_to_num(parameter_2)

		self.surface_type = ''
		self.peptide_size = ''
		self.peptide_length = None
		self.peptide_sequence = ''
		self.data_typer()
		
		self.test_condition = None
		self.parameter_group = None
		self.variation_group = None
		self.parameters_varied = 0
		self.report_strings()

		self.file_names = []
		self.scores = []
		self.helicities = []
		self.leucine_distances = []
		self.lysine_distances = []
		self.c_alpha_distances = []
		self.phis = []
		self.psis = []

		self.helix_count = np.array([0] * self.peptide_length)
		self.loop_count = np.array([0] * self.peptide_length)

		self.helicity_mean = None
		self.helicity_sd = None

		self.folder_helicity_analysis()
		self.local_readable_summary()
		self.post_process()

	def name_to_num(self, parameter):
		"""
		Method will take a folder name generated by submit_script_gen and 
		isolates the numerical value of the varied parameter, regardless of 
		1 or 2 variables
		"""
		if parameter in ["baseline", None]:
			return None

		elif 'baseline' in self.folder_name:
			return param_list[parameter]

		else:
			fix_text = self.folder_name.lower()

			# strip out the decoy count, ex: '.top100'
			fix_text = fix_text.split(".top")[0]

			# isolating parameter value (hard-coded to fit submit_script_gen)
			# the parameter value follows the parameter in the folder name
			text_split = fix_text.split(parameter + '_')[1]
			target_value = text_split.split('_')[0] 	# value will be first item

			# convert to float
			return float(target_value)

	def data_typer(self):
		"""
		Method takes folder name output from submit_script_gen and determines 
		which of the eight possible combinations of peptide sequence and length,   
		and surface type that folder contains, so that the data can be added to  
		the appropriate bin for analysis.
		"""
		for i in ['hydrophilic', 'hydrophobic']:
			if i in self.folder_name:
				self.surface_type = i

		peptide_length = '14mer' 	# early trials did not include the 7mer option
		for j in ['7mer', '14mer']:
			if j in str(self.folder_name):
				self.peptide_size = j
				self.peptide_length = int(j.replace('mer',''))

		for k in ['alpha', 'beta']:
			if k in self.folder_name:
				self.peptide_sequence = k

	def report_strings(self):
		""" Method concatenates various values for file naming """
		# Test condition
		self.test_condition = '_'.join([self.surface_type, 
										self.peptide_size, 
										self.peptide_sequence])

		# Adjusting parameter group to consistent float so plot names align
		par_1_string = str(self.parameter_1_value)
		par_2_string = str(self.parameter_2_value)
		for string in [par_1_string, par_2_string]:
			while len(string) < 5:
				if '.' in string:
					string += '0'
				else:
					string += '.'

		# Parameter group and parameters varied
		if self.parameter_1 is None and self.parameter_2 is None:
			self.parameter_group = 'baseline'
			self.parameters_varied = 0

		elif self.parameter_2 is None:
			self.parameter_group = '_'.join([self.parameter_1, par_1_string])
			self.parameters_varied = 1

		else:
			self.parameter_group = '_'.join([self.parameter_1, par_1_string,
											self.parameter_2, par_2_string])
			self.parameters_varied = 2

		# Variation group
		self.variation_group = self.surface_type + '_' + self.peptide_size

	def add_pose(self, pose_data):
		"""
		This function adds a pose_helicity_data class object to the group.
		"""
		self.file_names.append(pose_data.pose_name)
		self.scores.append(pose_data.score)
		self.helicities.append(pose_data.helicity)
		self.leucine_distances += pose_data.leucine_distances
		self.lysine_distances += pose_data.lysine_distances
		self.c_alpha_distances += pose_data.c_alpha_distances
		self.phis += pose_data.phis
		self.psis += pose_data.psis
		self.helix_count += pose_data.helix_hist
		self.loop_count += pose_data.loop_hist

	def folder_helicity_analysis(self):
		"""
		This method enables the class to collect all pose helicity analysis 
		data on each PDB in the input folder, and stores the combined data from 
		the entire folder, including the test condition, both parameters and 
		their values, the mean and standard deviation of helicity for all PDBs, 
		histogram data of residues are helical or non-helical in secondary 
		structure, and lists of files, scores, helicities, leucine and lysine z 
		coordinates, and backbone dihedral angles.
		"""
		# displaying folder name
		print "\n", self.folder_name, ":"

		# getting list of PDBs
		pdbs = join(self.location, "*.pdb.gz")
		pdb_list = glob(pdbs)
		pdb_list.sort()

		# Analyzing pose secondary structures and adding them to list
		for file_name in pdb_list:
			try:
				p = pose_from_pdb(file_name)

			except Exception: 
				print 'Unable to read ', file_name
				continue

			self.add_pose(pose_helicity_data(file_name))

	def post_process(self):
		"""
		This function calculates helicity mean and standard deviation. It also 
		converts the numpy arrays (helix and loop count) to lists for later 
		ease of use.
		"""
		# Getting average and sd of helicity
		self.helicity_mean = np.mean(self.helicities)
		self.helicity_sd = np.std(self.helicities)

		# Converting np arrays to lists
		self.helix_count = list(self.helix_count)
		self.loop_count = list(self.loop_count)
		
	def local_readable_summary(self):
		"""
		This method makes a reference text file listing the PDB file names, 
		helicities, and scores for all PDB's in the folder, sorted by score.
		"""
		# making a combined list
		name_heli_score = zip(self.file_names, self.helicities, self.scores)

		# sorting by score
		sorted_helicities = sorted(name_heli_score, key=lambda x: x[2])

		# saving file
		template = '{:50s} {:20s} {:10s} \n'
		local_out = join(self.location, 'scores_helicities.txt')
		with open(local_out, 'w') as l_o:
			l_o.write(template.format("File", "Helicity", "Score"))  # Header
			for line in sorted_helicities:
				lineout = [str(x) for x in line]
				l_o.write(template.format(*lineout))

##############################################################################
"""Analysis functions"""


def identify_parameters(place, parameter_1, parameter_2=None):
	"""
	This function takes the parameter arguments (or lack thereof) and 
	determines whether the dataset is baseline, or one or two varied 
	parameters, and which parameters are varied if applicable.  Default is 
	baseline.  If parameter arguments are given, this function will verify 
	that they are in the list of possible parameters.  If not, before 
	accepting default, the function will read the folder name and identify 
	parameters there.
	"""
	# default: baseline
	par_name = None

	# given input
	if parameter_1:
		par_name = parameter_1.lower()
		assert par_name in param_list

	# checking folder name
	else:
		for parameter in param_list:
			if parameter == parameter_2: 	# for second parameter case
				continue
			elif parameter in basename(place):
				par_name = parameter	

	return par_name


def display_parameters(directory_name, parameter_1, parameter_2, calc=True):
	"""
	This function uses identify_parameters function to determine one or two 
	varied parameters. It will display the filepath and parameters as well.
	"""
	# calculate parameters
	name_1 = identify_parameters(directory_name, parameter_1)
	name_2 = identify_parameters(directory_name, parameter_2, name_1)

	# display parameters
	print "\n\nPATH:\t" + directory_name

	if name_1 is None:
		print "\nBaseline\n"
	else:
		print "\nVaried Parameter:\t" + name_1 + '\n'

	if name_2 is not None:
		print "Varied Parameter:\t" + name_2 + '\n'

	# returning parameters
	if calc:
		return name_1, name_2


def master_data_extraction(path, parameter_1, parameter_2):
	"""
	This is the overall function for reading helicity data from a folder of 
	folders generated by submit_script_gen.  The data from each PDB in a 
	subfolder is collected in a class object, and all class objects are stored 
	in a list.  Each object will include the folder's test condition, and the 
	varried parameter(s) and parameter values if applicable.  It will also 
	include the helicity mean and standard deviation for the folder, a helix 
	count and loop count for each residue in the peptide, lists of file names, 
	PDB scores, and helicities for each PDB in the folder, and lists of the 
	leucine and lysine distances from the surface acrtoss all peptides and 
	residues in the folder.
	"""
	# identifying parameter(s) being analyzed
	par_name_1, par_name_2 = display_parameters(path, 
												parameter_1, 
												parameter_2)

	# getting list of subfolders
	subdirectories = next(walk(path))[1]
	subdirectories.sort()
	print "\nFolder list:"
	for subdirectory in subdirectories:
		print '\t' + subdirectory

	# Performing local helicity analysis
	global_datasets, excluded_folders = [[] for i in range(2)]
	print "\nReading PDB's"

	for folder in range(len(subdirectories)):
		place = join(path, subdirectories[folder])
		# verify that folder has PDBs (exclude plots folders, etc.)
		run = False
		for file in listdir(place):
			if '.pdb.gz' in file:
				run = True
				break

		# analyzing folder PDB's
		if run:
			fhd = folder_helicity_data(
				place, par_name_1, par_name_2)
			global_datasets.append(fhd)

		else:
			print "Excluding folder:", subdirectories[folder]
			excluded_folders.append(subdirectories[folder])

	# Making data dump text file
	folder_name = basename(path)
	master_out = join(path, folder_name + "_helicity_data.txt")
	with open(master_out, "wb") as f:
		pickle.dump(global_datasets, f, pickle.HIGHEST_PROTOCOL)

	return global_datasets

#############################################################################
"""Plotting functions"""


def make_octets(dataset_list):
	"""
    Local plots (the residue helicity histogram, the L/K surface distance 
    plot, Ramachandran, and the score-helicity scatterplot) show all surface/
    peptide combinations for a single test condition, e.g. baseline or a 
    single varied parameter value. This function takes the list of folder data 
    and sorts it into sets to pass to those plotting functions.
	"""
	# getting list of groups
	octet_groups = []
	for datum in dataset_list:
		if datum.parameter_group in octet_groups:
			continue
		else:
			octet_groups.append(datum.parameter_group)
	octet_groups.sort()

	# populating groups
	octets = []
	for i in range(len(octet_groups)):
		octets.append([])
		for datum in dataset_list:
			if datum.parameter_group == octet_groups[i]:
				octets[i].append(datum)

	return octets


def add_textline(text, x, y, ha='left', va='center', r=90, fs=11):
	"""	This function adds text labels to a figure """
	plt.figtext(x, y, text, horizontalalignment=ha, verticalalignment=va, 
				rotation=r, fontsize=fs, style='normal')


class local_helicity_plots:
	"""
	This class will generate the three local plot types, the residue helicity 
	histogram, the L/K surface distance plot, and the score-helicity 
   scatterplot. The reason for calling it an octet, even if there aren't eight 
   items, is because the figure has eight plot spaces, representing each 
   combination of surface type (hydrophilic or hydrophobic), peptide size 
   (7mer or 14mer), and peptide sequence (alpha or beta).
	"""
	def __init__(self, condition_octet, filepath, out_folder, black_white):
		self.octet = condition_octet
		self.path = filepath
		self.folder_name = out_folder
		self.condition = self.octet[0].parameter_group

		# Plot settings
		self.plot_types = {'heli_hist': self.helicity_plotter, 
							'surf_dist': self.distance_plotter, 
							'funnel': self.scatter_plotter,
							'rama':self.rama_plotter}
		self.color = {False: 0, True: 1}[black_white]

		# Getting min and max scores for funnel plots
		self.min_score = []
		self.max_score = []
		self.scatter_range()

		for plot_type in self.plot_types:
			print 'Making Plot:\t' + self.condition + '\t\t' + plot_type
			self.local_plot_master(plot_type)

	def scatter_range(self):
		""" Determining plot range for funnel-type scatter plots """
		# Finding absolute maxima and minima
		abs_min_score = min([min(data.scores) for data in self.octet])
		abs_max_score = max([max(data.scores) for data in self.octet])

		# Checking if max score is positive. Necessary for beta_november sets
		# because hydrophilic surface scores highly positive
		if abs_max_score < 0:
			self.min_score = [abs_min_score, abs_min_score]
			self.max_score = [abs_max_score, abs_max_score]

		# Splitting score ranges
		else:
			# Separating hydrophobic and hydrophilic
			hydrophilic_sets = []
			hydrophobic_sets = []
			for i in self.octet:
				if i.surface_type == 'hydrophilic':
					hydrophilic_sets.append(i)
				if i.surface_type == 'hydrophobic':
					hydrophobic_sets.append(i)

			# Finding set maxima and minima
			hydrophilic_min_score = \
				min([min(data.scores) for data in hydrophilic_sets])
			hydrophilic_max_score = \
				max([max(data.scores) for data in hydrophilic_sets])

			hydrophobic_min_score = \
				min([min(data.scores) for data in hydrophobic_sets])
			hydrophobic_max_score = \
				max([max(data.scores) for data in hydrophobic_sets])

			self.min_score = [hydrophilic_min_score, hydrophobic_min_score]
			self.max_score = [hydrophilic_max_score, hydrophobic_max_score]

	def local_plot_master(self, p_type):
		"""
		Structure for creating 4x2 plots of the three different local types.  
		Each subplot is populated by the appropriate type function.
		"""
		# creating a figure with eight plots arranged 4x2
		fig, axes = plt.subplots(nrows=2, ncols=2)

		# formatting and labeling plot
		axis_labels = {'heli_hist': ['Secondary Structure', 'Residue Number'], 
						'surf_dist': ['Relative Probability', 
										r'Distance from Surface ($\AA$)'], 
						'funnel': ['Score (REU)', 'Helicity'], 
						'rama': [r'$\psi$ (degrees)', r'$\phi$ (degrees)']}
		self.local_plot_formatter(fig, axis_labels[p_type])

		# mapping each dataset to the appropriate plot	
		set_2_plot = {	'hydrophilic_14mer_alpha': axes[0][0], 
						'hydrophilic_14mer_beta': axes[0][1],
						'hydrophobic_14mer_alpha': axes[1][0], 
						'hydrophobic_14mer_beta': axes[1][1], 
						'hydrophilic_7mer_alpha': axes[0][0], 
						'hydrophilic_7mer_beta': axes[0][1],
						'hydrophobic_7mer_alpha': axes[1][0], 
						'hydrophobic_7mer_beta': axes[1][1]}

		# populating each plot
		for data in self.octet:
			plot_data = {
				'heli_hist': [data.helix_count, data.loop_count], 
				'surf_dist': [data.leucine_distances, 
								data.lysine_distances, 
								data.c_alpha_distances], 
				'funnel': [data.scores, data.helicities, data.surface_type], 
				'rama':[data.phis, data.psis]}

			self.plot_types[p_type](set_2_plot[data.test_condition], 
									plot_data[p_type])

		# Removing superfluous ticks
		if p_type != 'funnel': 	# Scores not necessarily the same for all 4
			for a in [a[1] for a in axes]: 	#Plots on the right
				a.set_yticklabels(())
		else: 					# Leave space for scores
			plt.subplots_adjust(wspace=0.37)

		for a in axes[0]: 	# Plots on the top
			a.set_xticklabels(())

		# Setting tick fonts
		for a in [axes[0][0], axes[0][1], axes[1][0], axes[1][1]]:
			for t in a.xaxis.get_major_ticks() + a.yaxis.get_major_ticks():
				t.label.set_fontsize(10)

		# saving figure
		title = {'heli_hist': '_sec_struct_distribution_', 
					'surf_dist': '_distance_distribution_', 
					'funnel': '_helicity_vs_score_', 
					'rama': '_rama_'}
		p_name = join(self.path, self.folder_name + title[p_type] + 
								self.condition + '.png')
		plt.savefig(p_name, dpi=300, transparent=True)
		plt.close()

	def local_plot_formatter(self, fig, y_x_labels):
		"""
		Applies standard formatting and labels to 4x2 local data plots
		"""
		# formatting
		fig.set_size_inches(3.5, 2.5)
		#plt.subplots_adjust(hspace = 0.3)
		#plt.subplots_adjust(wspace = 0.25)
		fig.subplots_adjust(top=0.9, bottom=0.18, left=0.18, right=0.89)

		# labels
		add_textline(y_x_labels[0], 0.02, 0.535, fs=12)
		add_textline(y_x_labels[1], 0.535, 0.03, 
					ha='center', va='bottom', r=0, fs=12)
		add_textline(r'LK-$\alpha$', 0.34, 0.98, ha='center', va='top', r=0)
		add_textline(r'LK-$\beta$', 0.74, 0.98, ha='center', va='top', r=0)
		add_textline('Hydrophobic', 0.91, 0.34)
		add_textline('Hydrophilic', 0.91, 0.745)

	def helicity_plotter(self, ax, helix_loop_hist_data):
		"""
		Generates a bar plot with bins for each of the residues in the peptide, 
		with red indicating the number of decoys in the set in which that 
        residue is helical, and blue indicating the number of decoys in which 
        it is not helical
		"""
		width = 1

		assert len(helix_loop_hist_data[0]) == len(helix_loop_hist_data[1])
		bin_count = len(helix_loop_hist_data[0])
		bins = np.arange(0, bin_count)+0.5

		ax.bar(	bins, helix_loop_hist_data[0], width, 
				color=['red', 'gray'][self.color])
		ax.bar(	bins, helix_loop_hist_data[1], width, 
				color=['blue', 'white'][self.color], 
				bottom=helix_loop_hist_data[0])

		ax.axis([width / 2.0, bin_count + width / 2.0, 0, 
				max(helix_loop_hist_data[0] + helix_loop_hist_data[1])])
		ax.xaxis.set_major_locator(plt.MaxNLocator(5))		

	def distance_plotter(self, ax, L_K_z_coords):
		"""
		Generates a double lineplot showing the distance distribution 
		frequency of leucine any lysine residues for all peptides in the 
		folder, with lysine in red and leucine in blue.
		"""
		# Generating bins based on range of distances
		L_count, x_L = np.histogram(L_K_z_coords[0], bins=50, range=(0, 25))
		K_count, x_K = np.histogram(L_K_z_coords[1], bins=50, range=(0, 25))
		C_count, x_C = np.histogram(L_K_z_coords[2], bins=50, range=(0, 25))
		x_L = x_L[:-1] + (x_L[1] - x_L[0]) / 2
		x_K = x_K[:-1] + (x_K[1] - x_K[0]) / 2
		x_C = x_C[:-1] + (x_C[1] - x_C[0]) / 2
		f_L = UnivariateSpline(x_L, L_count, s=50)
		f_K = UnivariateSpline(x_K, K_count, s=50)
		f_C = UnivariateSpline(x_C, C_count, s=50)

		# Normalizing L/K distances
		max_L, min_L = max(f_L(x_L)), min(f_L(x_L))
		max_K, min_K = max(f_K(x_K)), min(f_K(x_K))
		max_C, min_C = max(f_C(x_C)), min(f_C(x_C))
		l_norm = [(float(i) - min_L)/(max_L-min_L) for i in f_L(x_L)]
		k_norm = [(float(i) - min_K)/(max_K-min_K) for i in f_K(x_K)]
		c_norm = [(float(i) - min_C)/(max_C-min_C) for i in f_C(x_C)]

		# plotting
		c = self.color
		ax.plot(x_K, k_norm, label="Lysine", lw=1.5, 
				color=['red', 'gray'][c], linestyle=['-', '--'][c])
		ax.plot(x_L, l_norm, label="Leucine", lw=1.5, 
				color=['blue', 'gray'][c], linestyle=['-', ':'][c])
		ax.plot(x_C, c_norm, label="CA", lw=1, 
				color='black', linestyle=['-', '-:'][c])

		ax.axis([-0.5, 25.5, -0.04, 1.04])

	def scatter_plotter(self, ax, scores_helicities):
		"""
		Generates a scatter of score vs helicity.  This plot approximates a 
		funnel plot, with helicity taking the place of RMSD.
		"""
		ax.scatter(scores_helicities[1], scores_helicities[0], 
					s=4, color=['blue', 'gray'][self.color])

		# setting axis limits so points aren't right on axis lines
		which_scores = ['hydrophilic', 'hydrophobic'].index(
				scores_helicities[2])
		w = which_scores
		margin = 0.06 * (self.max_score[w] - self.min_score[w])
		m = margin
		ax.axis([-0.04, 1.04, self.min_score[w] - m, self.max_score[w] + m])

		# setting a max tick count on the Y axis so the numbers don't overlap
		max_ticks = 5
		loc = plt.MaxNLocator(max_ticks)
		ax.xaxis.set_major_locator(loc)
			#ax.yaxis.set_major_locator(loc)

	def rama_plotter(self, ax, phi_psis):
		""" Generates a Ramachandran scatter plot. """
		# Original plot
		ax.scatter(phi_psis[0], phi_psis[1], s=0.4, facecolors='none', linewidth=0.1,
					color=['blue', 'gray'][self.color])

		# Trying to add heats
		## Calculate point densities
		#stacked = np.vstack(phi_psis)
		#heat = gaussian_kde(stacked)(stacked)

		## Sort by densities, plotting hot points last
		#sorting = heat.argsort()
		#x = np.array(phi_psis[0])[sorting], 
		#y =	np.array(phi_psis[1])[sorting], 
		#z = heat[sorting]

		## Plotting
		#ax.scatter(x, y, s=0.5, edgecolor='', color=[z, 'gray'][self.color])

		# Trying histogram
		#ax.hist2d(phi_psis[0], phi_psis[1], (30,30), cmap=plt.cm.jet)

		# Setting axis limits and tick counts
		ax.axis([-180, 180, -180, 180])
		max_ticks = 5
		loc = plt.MaxNLocator(max_ticks)
		ax.yaxis.set_major_locator(loc)
		ax.xaxis.set_major_locator(loc)

		# Adding lines at 0
		ax.plot([0, 0], [-180, 180], '-', lw=0.5, color="black")
		ax.plot([-180, 180], [0, 0], '-', lw=0.5, color="black")


def surf_size_cluster(dataset_list):
	"""
	This function takes the list of folder data and sorts it into sets of 
	consistent surface type and peptide size (peptide sequence is mixed a/b). 
	These groups are passed to the varied parameter plots.
	"""
	# getting list of groups
	surf_size_groups = []
	for datum in dataset_list:
		if datum.variation_group not in surf_size_groups:
			surf_size_groups.append(datum.variation_group)

	# surf_size_groups.sort()

	# populating groups
	quadrants = [] 
	for i in range(len(surf_size_groups)):
		quadrants.append([])
		for datum in dataset_list:
			if datum.variation_group == surf_size_groups[i]:
				quadrants[i].append(datum)

	# splitting groups into alpha and beta
	quads_split = []
	for quadrant in quadrants:
		alpha_list, beta_list = [[] for i in range(2)]
		for datum in quadrant:
			if datum.peptide_sequence == 'alpha':
				alpha_list.append(datum)
			elif datum.peptide_sequence == 'beta':
				beta_list.append(datum)
		quads_split.append([alpha_list, beta_list])

	return quads_split


class parameter_varriation_plots:
	"""
	Whereas the local helicity plots compare the eight surface/peptide 
	combinations at a single experimental condition or at baseline, this class
	is intended to handle larger data sets that include the variation of one 
	or two parameters. The reason for calling the data a quadrant, even if 
	there aren't four of them, is due to the nature of the figure taking both 
	alpha and beta data from one of four possible combinations of surface 
	(hydrophilic or hydrophobic) and peptide size (7mer or 14mer).
	"""
	def __init__(self, a_list, b_list, filepath, folder_name, black_white):
		self.alpha_sets = a_list
		self.beta_sets = b_list
		self.path = filepath
		self.folder_name = folder_name
		self.variation_group = a_list[0].variation_group 		# same for all
		self.parameters_varied = a_list[0].parameters_varied 	# same for all
		self.parameter_1 = a_list[0].parameter_1 				# same for all
		self.parameter_2 = a_list[0].parameter_2 				# same for all

		self.match_param_values = ['parameter_1_value', 'parameter_2_value', 
									'helicity_mean', 'helicity_sd', 'scores', 
									'helicities']

		# initializing list parameters
		for seq in ['alpha_', 'beta_']:
			for param in self.match_param_values:
				setattr(self, seq + param, [])
			for coord in ['x', 'y', 'z']:
				setattr(self, seq + '2_var_' + coord, [])
		for coord in ['x', 'y', 'z']:
			setattr(self, 'difference_2_var_' + coord, [])

		self.one_var_plots = {'1-var_plot': self.helicity_parameter_plot, 
							'score-helicity_plot': self.score_helicity_plot}
		self.color = {False: 0, True: 1}[black_white]
		
		# incorporating data
		for seq in ['alpha_', 'beta_']:
			for trial in getattr(self, seq + 'sets'):
				for param in self.match_param_values:
					getattr(self, seq + param).append(getattr(trial, param))

		# plotting
		if self.parameters_varied == 1:
			for p_type in self.one_var_plots:
				print '\t'.join(['Making Plot:', self.variation_group, p_type])
				self.one_var_plots[p_type]()

		elif self.parameters_varied == 2:
			self.two_var_grid()
			print '\t'.join(['\nMaking Plot:', 
							self.variation_group, 
							'2-var plot'])
			self.two_var_heat_plot()

	def plot_namer(self, name):
		""" Makes plot name form path, parameters, given text """
		if self.parameter_2 is None:
			p2_text = ''
		else:
			p2_text = '_' + self.parameter_2

		return join(self.path, self.folder_name + name + self.parameter_1 + 
						p2_text + "_" + self.variation_group + ".png")

	def helicity_parameter_plot(self):
		"""
		Generates a line plot, with a red line for alpha-sequence peptides and 
		a blue line for beta-sequence peptides, which shows the average 
		helicity of the set as a single score weight or surface atom property 
		is varied.  A vertical dotted black line indicates the Talaris2013 
		default value for the varied parameter, and error bars at each point 
		indicate the standard deviation in the dataset.
		"""
		fig, ax0 = plt.subplots(nrows=1, ncols=1)

		c = self.color

		# Converting weight value to fraction of default
		par_default = param_list[self.parameter_1]
		alpha_x = [round(i / par_default,2) for i in self.alpha_parameter_1_value]
		beta_x = [round(i / par_default, 2) for i in self.beta_parameter_1_value]

		# helicity vs parameter lines
		ax0.plot(alpha_x, self.alpha_helicity_mean, 
			color=['red', 'gray'][c], linestyle=['-', '--'][c], lw=1.5)
		ax0.plot(beta_x, self.beta_helicity_mean, 
			color=['blue', 'gray'][c], linestyle=['-', '-.'][c], lw=1.5)

		# default line
		ax0.plot([1, 1], [0, 1], 
						'--', lw=1, color="black")

		# error bars
		ax0.errorbar(alpha_x, self.alpha_helicity_mean, 
						yerr = self.alpha_helicity_sd,  
						color=['red', 'gray'][c], lw=0.5)
		ax0.errorbar(beta_x, self.beta_helicity_mean, 
						yerr=self.beta_helicity_sd, 
						color=['blue', 'gray'][c], lw=0.5)

		# axes
		#ax0.set_xlabel(self.parameter_1.upper(), fontsize=14)
		ax0.set_ylabel("Helicity", fontsize=12)
		#max_pt = max(self.alpha_parameter_1_value + 
        #                self.beta_parameter_1_value)
		#margin = 0.04 * (max_pt)
		#ax0.axis([-margin, max_pt + margin, -0.04, 1.04])
		ax0.axis([-0.1, 2.1, -0.04, 1.04])
		max_ticks = 3
		loc = plt.MaxNLocator(max_ticks)
		ax0.xaxis.set_major_locator(loc)

		# Size
		fig.set_size_inches(1.75, 1.5)
		fig.subplots_adjust(bottom=0.25, top=0.95, left=0.3, right=0.9)
		for t in ax0.xaxis.get_major_ticks() + ax0.yaxis.get_major_ticks():
				t.label.set_fontsize(10)

		# save plot
		plt.savefig(self.plot_namer("_prarmeter_helicity_plot_"), dpi=300)
		plt.close()

	def score_heli_axis_limits(self):
		""" Sets axis limits for score-helicity plots """
		# Determining score range
		scores = self.alpha_scores + self.beta_scores
		y_max = max([max(i) for i in scores])
		y_min = min([min(i) for i in scores])

		# Getting axis limits
		margin = 0.06 * (y_max - y_min) 	# prevents points being cut off
		ax_min, ax_max = y_min - margin, y_max + margin
		axlims = [-0.06, 1.06, ax_min, ax_max]

		return axlims


	def colormapper(self, scorelist):
		""" Generate iterable cmap patterns for use in score_helicity_plot """
		if self.color == 0:
			colors = iter(cm.rainbow(np.linspace(0, 1, len(scorelist))))
			markers = iter(['o'] * len(scorelist))
		else: 
			colors = iter(['gray'] * len(scorelist))
			markers = iter(['o', 's', 'D', '^', 'h', 'p', '*', 
								'v', 'd', '8', '>', '<', 'H'])

		return colors, markers

	def score_helicity_plot(self):
		"""
		Generates a pair of scatterplots intended to mimic score-RMSD funnel 
		plots. The first represents the alpha sequence peptides, and the second 
		the beta sequence peptides. The plot coordinates for each decoy are its 
		score and its helicity. This plot includes the data from all subsets.
		"""	
		fig, ax = plt.subplots(nrows=2, ncols=1)

		# alpha plot
		colors, markers = self.colormapper(self.alpha_scores)
		legend_keys = []
		for group in range(len(self.alpha_scores)):
			key = ax[0].scatter(self.alpha_helicities[group], 
									self.alpha_scores[group], s=10, alpha=0.6, 
									c=next(colors), marker=next(markers))
			legend_keys.append(key)

		# beta plot
		colors, markers = self.colormapper(self.beta_scores)
		for group in range(len(self.beta_scores)):
			ax[1].scatter(self.beta_helicities[group], 
							self.beta_scores[group], s=10, alpha=0.6, 
							c=next(colors), marker=next(markers))
		ax[1].set_xlabel("Helicity", fontsize=14)

		# Setting axis limits and ticks
		axis_limits = self.score_heli_axis_limits()
		for a in ax:
			a.axis(axis_limits)
			a.set_xticks([0 ,0.5, 1])
			cur_y_ticks = a.get_yticks()
			a.set_yticks(cur_y_ticks[1:-1:2])


		# Y labels
		plt.figtext(0.02, 0.525, 'Score', horizontalalignment='left', 
			verticalalignment='center', rotation=90, fontsize=14)
		plt.figtext(0.71, 0.76, r'LK-$\alpha$', horizontalalignment='left', 
			verticalalignment='center', rotation=90, fontsize=12)
		plt.figtext(0.71, 0.34, r'LK-$\beta$', horizontalalignment='left', 
			verticalalignment='center', rotation=90, fontsize=12)

		# legend
			#title
		title_switches = {	'hbond_sr_bb': 'hbond', 
							'lj_wdepth': 'wdepth', 
							'lk_volume': 'volume'}
		if self.parameter_1 in title_switches:
			title = title_switches[self.parameter_1]
		else:
			title = self.parameter_1

		assert self.alpha_parameter_1_value == self.beta_parameter_1_value
		fig.legend(legend_keys, self.alpha_parameter_1_value, ncol=1, 
					bbox_to_anchor=[0,0.05,1,0.9], loc='center right', 
					scatterpoints=1, fontsize=8, 
					title=title.upper())

		# Size
		fig.subplots_adjust(bottom=0.2, top=0.9, left=0.2, right=0.69)
		fig.set_size_inches(3.5, 2.25)
		plt.subplots_adjust(hspace = 0.5)
		plt.subplots_adjust(wspace = 0.25)

		# save plot
		plt.savefig(self.plot_namer("_score_plot_"), dpi=300)
		plt.close()

	def two_var_grid(self):
		"""
		The two-variable heat map is essentially 3-D, and therefore requires 
        the parameter values and helicities to be arrayed.  This function does 
        that.
		"""
		for seq in ['alpha_', 'beta_']:
			# making x and y coordinate arrays
			vals_1 = sorted(list(set(getattr(self, seq + 'parameter_2_value')))) 
			vals_2 = sorted(list(set(getattr(self, seq + 'parameter_1_value'))))
			x, y = np.meshgrid(vals_1, vals_2)
			setattr(self, seq + '2_var_x', x)
			setattr(self, seq + '2_var_y', y)

			# making z coordinate array
			x_length = len(vals_1)
			y_length = len(vals_2)
			z = np.zeros((y_length, x_length))

			for datum in getattr(self, seq + 'sets'):
				x_index = vals_1.index(datum.parameter_2_value)
				y_index = vals_2.index(datum.parameter_1_value)
				z[y_index][x_index] = datum.helicity_mean

			setattr(self, seq + '2_var_z', z)

		# making alpha - beta difference array
		assert all(self.alpha_2_var_x) == all(self.beta_2_var_x)
		setattr(self, 'difference_2_var_x', self.alpha_2_var_x)
		assert all(self.alpha_2_var_y) == all(self.beta_2_var_y)
		setattr(self, 'difference_2_var_y', self.alpha_2_var_y)

		delta = self.alpha_2_var_z - self.beta_2_var_z
		setattr(self, 'difference_2_var_z', delta)

	def heat_plotter(self, which_plot):
		"""
		This function makes heat plots for the subsections of the 
		two_var_heat_plot function.  which_plot refers to alpha, beta, or 
        delta.
		"""
		subplot = {'alpha': 221, 'beta': 222, 'difference': 212}

		ax = plt.subplot(subplot[which_plot])
		x = getattr(self, which_plot + '_2_var_x')
		y = getattr(self, which_plot + '_2_var_y')
		z = getattr(self, which_plot + '_2_var_z')
		if which_plot in ['alpha', 'beta']:
			cs = ax.contourf(x, y, z, vmin=0, vmax=1, 
							cmap=[cm.coolwarm, cm.gray][self.color], 
							levels=np.arange(0, 1.1, 0.1))
		else:
			cs = ax.contourf(x, y, z, cmap=[cm.RdYlGn, cm.gray][self.color])

		# Points
		ax.scatter(x, y, color="black", marker='o', edgecolor='white')
		title = which_plot.upper()
		ax.set_title(title, fontsize=18)
		for t in ax.xaxis.get_major_ticks() + ax.yaxis.get_major_ticks():
			t.label.set_fontsize(11)

		# Default
		ax.scatter([0.52], [3], color='white', edgecolor='purple', 
                    marker='o', s=30)

		# Setting axis limits and tick counts
		ax.axis([-10.5, 1, 0, 20])
		#plt.xticks(list(plt.xticks()[0]) + [0.52])
		#plt.yticks(list(plt.xticks()[0]) + [0])

		return cs

	def two_var_heat_plot(self):
		"""
		Generates heat plots displaying the average helicity of the dataset at 
		each point in the two parameter grid.  The top plots represent the alpha 
		sequence and beta sequence peptides, while the bottom plot is the 
		difference between the two.
		"""
		axes = []
		fig = plt.figure()

		for subplot in ['alpha', 'beta', 'difference']:
			ax = self.heat_plotter(subplot)
			axes.append(ax)

		# formatting
		plt.subplots_adjust(hspace=0.3)
		plt.subplots_adjust(wspace=0.2)
		fig.subplots_adjust(top=0.9, bottom=0.12, left=0.11, right=0.85)
		plt.figtext(0.02, 0.525, 'Hydrophobic Surface LK_DGFREE', fontsize=16, 
						rotation=90, va='center')
		plt.figtext(0.475, 0.02, r'Lysine C$\epsilon$ LK_DGFREE', fontsize=16, 
						ha='center')
		plt.figtext(0.91, 0.915, 'HELICITY', fontsize=16, ha='center')

		# colorbars
		color_ax_1 = fig.add_axes([0.89, 0.565, 0.025, 0.33])
		fig.colorbar(axes[1], cax=color_ax_1)
		color_ax_2 = fig.add_axes([0.89, 0.125, 0.025, 0.33])
		fig.colorbar(axes[2], cax=color_ax_2)

		# Size
		fig.set_size_inches(7, 5)

		# save plot
		plt.savefig(self.plot_namer("_helicity_heat_plot_"), dpi=300)
		plt.close()

#############################################################################


def main():
	args = parse_args()

	# setting path, eliminating extra '/', lowering case
	path = normpath(join(getcwd(), args.folder))

	# isolating folder name
	directory_name = basename(path)

	# getting data, either by folder analysis, or by reading the dump file
	# if the analysis has previously been run
	if args.calculate: 
		opts = '-include_surfaces -mute core'
		rosetta.init(extra_options=opts)

		datasets = master_data_extraction(	path, 
											args.parameter_1, 
											args.parameter_2)

	else:
		# display path and varied parameter(s)
		display_parameters(path, args.parameter_1, args.parameter_2, 
							calc=False)

		# importing the saved data from previous calculation
		master_out = join(path, directory_name + "_helicity_data.txt")
		with open(master_out, "rb") as f:
			datasets = pickle.load(f)

	# sort datasets by parameter 1 and parameter 2 values
	datasets.sort(key=operator.attrgetter(
		'test_condition', 'parameter_1_value', 'parameter_2_value'))

	# making plots folder
	plots_folder = join(path, directory_name + '_plots')
	if not isdir(plots_folder):
			makedirs(plots_folder)
	
	# plotting
	print "\nPlotting"

	# Generating local plots
	octet_groups = make_octets(datasets)
	if not args.skip_local:
		for group in octet_groups:
		 	local_helicity_plots(	group, 
		 							plots_folder, 
		 							directory_name, 
		 							args.black_white)

	# no aggregate plotting possible for baselines
	if len(octet_groups) == 1:
		print '\n'
		exit()
	
		# parameter variation plots
	var_groups = surf_size_cluster(datasets)
	for group in var_groups:
		parameter_varriation_plots(	group[0], 
									group[1], 
									plots_folder, 
									directory_name,
									args.black_white)

	print '\n'

def quick_check(file, sets=4):
	""" 
	Function for quickly viewing helicity and discrimination data in an  
	interactive session. Reads from a helicity_data.txt data dump file.
	"""
	# Reading score file
	with open(file, "rb") as f:
		datasets = pickle.load(f)

	set_size = len(datasets)
	template = '{:30s}{:30s}{:20s}'
	print template.format('Peptide', 'Parameters', 'Helicity')

	# Printing helicities
	for i in range(set_size):
		readout = [datasets[i].test_condition, 
					datasets[i].parameter_group, 
					str(datasets[i].helicity_mean)]
		print template.format(*readout)

	# Printing discriminations
	half = set_size / 2

	if sets == 2:
		for i in range(half):
			readout = [datasets[i].variation_group, 
						datasets[i].parameter_group, 
						str(datasets[i].helicity_mean - 
							datasets[i + half].helicity_mean)]
			print template.format(*readout)

	elif sets == 4:
		quar = set_size / 4
		for i in range(quar) + range(half, half + quar):
			readout = [datasets[i].variation_group, 
						datasets[i].parameter_group, 
						str(datasets[i].helicity_mean - 
							datasets[i + quar].helicity_mean)]
			print template.format(*readout)

	
if __name__ == '__main__':
	main()
